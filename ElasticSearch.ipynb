{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Elasticsearch\n",
    "* **Elasticsearch** is a distributed search and analytics engine designed to handle large-scale data.\n",
    "* It can scale horizontally by adding more nodes to the cluster, making it capable of handling high-volume data and providing fast search responses.\n",
    "* ES stores and indexes data in the form of JSON documents.\n",
    "  * Each document contains one or more fields with their corresponding values.\n",
    "  * Data is indexed in ES by specyfying an index, type and ID for each document. \n",
    "* ES offers excellent search capabilities, including full-text search, filtering, aggregation etc.\n",
    "* It provides a Query DSL (Domain-Specific Language) that allows you to construct complex queries using JSON-like syntax.\n",
    "* It indexes and analyzes data to enable fast and accurate search results across various types of documents.\n",
    "\n",
    "For more detailed information about Elasticsearch and its features, you can visit the official website:\n",
    "[**Elasticsearch Official Website**](https://www.elastic.co/elasticsearch/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elasticsearch Python Library\n",
    "* The **Python Elasticsearch** library is the official Python client for Elasticsearch. \n",
    "* It provides a high-level and low-level interface to interact with Elasticsearch\n",
    "* You can install elasticsearch using ```pip3 install elasticsearch``` from your terminal or ```!pip3 install elasticsearch``` in notebook :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ES password: ········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "config = {\n",
    "    \"ES_USER\": \"elastic\",\n",
    "    \"ES_PASS\": getpass(\"ES password: \")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'title': 'NumPy',\n",
       "  'description': 'NumPy is a powerful python library with many functions for creating and manipulating multi-dimensional arrays and matrices.'},\n",
       " {'id': 2,\n",
       "  'title': 'Pandas',\n",
       "  'description': 'Pandas is a Python library for data manipulation and analysis. It provides data structures for efficient storage of data and high-level manipulations.'},\n",
       " {'id': 3,\n",
       "  'title': 'Scikit-Learn',\n",
       "  'description': 'Scikit-Learn is a popular library for machine learning in Python. It provides tools to build, train, evaluate, and deploy machine learning algorithms.'},\n",
       " {'id': 4,\n",
       "  'title': 'Matplotlib',\n",
       "  'description': 'Matplotlib is a Python plotting library for creating publication quality plots. It can produce line graphs, histograms, power spectra, bar charts, and more.'},\n",
       " {'id': 5,\n",
       "  'title': 'Seaborn',\n",
       "  'description': 'Seaborn is a graphical library in Python for drawing statistical graphics. It provides a high level interface for drawing attractive statistical graphics.'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%store -r data\n",
    "data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elasticsearch Client** class represents the Elasticsearch client and is used to establish a connection with an Elasticsearch cluster. You can create an instance of the client by specifying the Elasticsearch host and port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cloud id: ········\n"
     ]
    }
   ],
   "source": [
    "es = Elasticsearch(\n",
    "    cloud_id=getpass(\"cloud id: \"), \n",
    "    basic_auth=(config['ES_USER'], config['ES_PASS']),\n",
    "    request_timeout=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the connection with ES host, you can use `es.ping()`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Elasticsearch.\n"
     ]
    }
   ],
   "source": [
    "if es.ping():\n",
    "    print(\"Connected to Elasticsearch.\")\n",
    "else:\n",
    "    print(\"Failed to connect to Elasticsearch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Instead of using host and id, I am using cloud_id and basic_auth with username and password.\n",
    "* To establish a connection to Elastic Cloud using the Python Elasticsearch client, it is recommended to utilize the cloud_id parameter. You can locate this value on the \"Manage Deployment\" page, which becomes accessible after creating a cluster. In Kibana, you can find it in the top-left corner of the page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index Management\n",
    "* Elasticsearch library provides functions for managing indices such as creating, deleting, checking the existence of an index, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index exists\n"
     ]
    }
   ],
   "source": [
    "# Create an index\n",
    "es.indices.create(index='test')\n",
    "\n",
    "# Check if an index exists\n",
    "if es.indices.exists(index='test'):\n",
    "    print(\"Index exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index doesn't exist\n"
     ]
    }
   ],
   "source": [
    "# Delete an index\n",
    "es.indices.delete(index='test')\n",
    "\n",
    "if es.indices.exists(index='test'):\n",
    "    print(\"Index exists\")\n",
    "else:\n",
    "    print(\"Index doesn't exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Indexing\n",
    "* You can index documents in Elasticsearch using the index function. \n",
    "* By indexing a document in ES you should understand - adding data to the database in a structured manner, like filling information in folders, so that it can be quickly searched and retrieved later on.\n",
    "* This allows Elasticsearch to efficiently organize and find specific information, making it easier to work with large amounts of data.\n",
    "* The document is represented as a Python dictionary and is associated with an index, type, and an optional ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index exists\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'_index': 'example', '_id': '1', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 0, '_primary_term': 1})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an example document\n",
    "example_doc = {\n",
    "    \"title\": 'Example Document',\n",
    "    \"content\": \"Content of an example document.\"\n",
    "}\n",
    "\n",
    "# Create an index\n",
    "es.indices.create(index='example')\n",
    "\n",
    "# Check if an index exists\n",
    "if es.indices.exists(index='example'):\n",
    "    print(\"Index exists\")\n",
    "else:\n",
    "    print(\"Index doesn't exist.\")\n",
    "\n",
    "# Index a document\n",
    "es.index(index='example', id=1, document=example_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `_index`: Indicates the name of the index where the document was indexed, in this case, 'example'.\n",
    "* `_id`: Represents the unique identifier assigned to the indexed document, which is '1' in this case.\n",
    "* `_version`: Denotes the version of the document after indexing, which is '1'.\n",
    "* `result`: Indicates the result of the indexing operation. In this case, it is 'created', indicating that the document was successfully created and indexed.\n",
    "* `_shards`: Provides information about the number of shards involved in the indexing process. Shards are smaller units of the index distributed across nodes in a cluster. In this case, 'total' is 2, indicating that the operation involved two shards, and 'successful' is 2, meaning the indexing was successful on all shards.\n",
    "* `_seq_no` and `_primary_term`: These terms relate to Elasticsearch's internal versioning system, which helps maintain consistency and handle conflicts in distributed environments. They represent specific details about the internal versioning of the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Retrieval\n",
    "* You can retrieve documents from ES using various methods like `get`, `search` etc. \n",
    "  * These methods allow you to query and filter the documents based on specific criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_index': 'example', '_id': '1', '_version': 1, '_seq_no': 0, '_primary_term': 1, 'found': True, '_source': {'title': 'Example Document', 'content': 'Content of an example document.'}}\n"
     ]
    }
   ],
   "source": [
    "# Get a document by ID\n",
    "result = es.get(index='example', id=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Example Document', 'content': 'Content of an example document.'}\n"
     ]
    }
   ],
   "source": [
    "doc = result['_source']\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `doc = result['_source']` is used to access the actual source data of the document from the response, allowing you to work directly with the document's fields and values without additional parsing or extraction steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Search documents\n",
    "query = {\n",
    "        'match': {\n",
    "            'title': 'Example Document'\n",
    "        }\n",
    "    }\n",
    "\n",
    "results = es.search(index='example', query=query)\n",
    "hits = results['hits']['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'took': 2, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 1, 'relation': 'eq'}, 'max_score': 0.5753642, 'hits': [{'_index': 'example', '_id': '1', '_score': 0.5753642, '_source': {'title': 'Example Document', 'content': 'Content of an example document.'}}]}}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_index': 'example', '_id': '1', '_score': 0.5753642, '_source': {'title': 'Example Document', 'content': 'Content of an example document.'}}]\n"
     ]
    }
   ],
   "source": [
    "print(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index doesn't exist.\n"
     ]
    }
   ],
   "source": [
    "es.indices.delete(index='example')\n",
    "\n",
    "# Check if an index exists\n",
    "if es.indices.exists(index='example'):\n",
    "    print(\"Index exists\")\n",
    "else:\n",
    "    print(\"Index doesn't exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bulk Operations\n",
    "* The library provides the bulk function to perform bulk operations like indexing, updating, deleting multiple documents in a single API call, which can significantly improve indexing performance.\n",
    "* The bulk API accepts a list of action items, where each item represents a specific operation to be performed on a document.\n",
    "* Each action item consists of a combination of an operation (index, update, delete) and the corresponding document data.\n",
    "* You can include multiple action items in a single bulk request to perform various operations simultaneously.\n",
    "\n",
    "I will use `data` list of dictionaries as my documents to create bulk actions. We will need another index for this purpose.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'title': 'NumPy',\n",
       "  'description': 'NumPy is a powerful python library with many functions for creating and manipulating multi-dimensional arrays and matrices.'},\n",
       " {'id': 2,\n",
       "  'title': 'Pandas',\n",
       "  'description': 'Pandas is a Python library for data manipulation and analysis. It provides data structures for efficient storage of data and high-level manipulations.'},\n",
       " {'id': 3,\n",
       "  'title': 'Scikit-Learn',\n",
       "  'description': 'Scikit-Learn is a popular library for machine learning in Python. It provides tools to build, train, evaluate, and deploy machine learning algorithms.'},\n",
       " {'id': 4,\n",
       "  'title': 'Matplotlib',\n",
       "  'description': 'Matplotlib is a Python plotting library for creating publication quality plots. It can produce line graphs, histograms, power spectra, bar charts, and more.'},\n",
       " {'id': 5,\n",
       "  'title': 'Seaborn',\n",
       "  'description': 'Seaborn is a graphical library in Python for drawing statistical graphics. It provides a high level interface for drawing attractive statistical graphics.'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index exists\n",
      "Data successfully indexed in the destination index.\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch.helpers import bulk, BulkIndexError\n",
    "\n",
    "# Create an index\n",
    "py_indexname = 'py-libraries'\n",
    "es.indices.create(index=py_indexname)\n",
    "\n",
    "# Check if an index exists\n",
    "if es.indices.exists(index=py_indexname):\n",
    "    print(\"Index exists\")\n",
    "else:\n",
    "    print(\"Index doesn't exist.\")\n",
    "\n",
    "actions = [\n",
    "    {\"_index\": py_indexname, \n",
    "     \"_id\": doc[\"id\"], \n",
    "     \"_source\": {\n",
    "          \"library\": doc[\"title\"],\n",
    "          \"description\": doc[\"description\"]}\n",
    "    }\n",
    "    for doc in data\n",
    "]\n",
    "\n",
    "try:\n",
    "    bulk(es, actions)\n",
    "    print(\"Data successfully indexed in the destination index.\")\n",
    "except BulkIndexError as e:\n",
    "    print(\"Failed to index documents:\")\n",
    "    for err in e.errors:\n",
    "        print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `bulk()` method takes the Elasticsearch client instance (es), the list of actions (actions), and the index name. It returns a response containing information about the bulk operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'count': 53, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = {\n",
    "        \"match_all\": {}\n",
    "}\n",
    "    \n",
    "es.count(index=py_indexname, query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'library': 'NumPy', 'description': 'NumPy is a powerful python library with many functions for creating and manipulating multi-dimensional arrays and matrices.'}\n",
      "{'library': 'Pandas', 'description': 'Pandas is a Python library for data manipulation and analysis. It provides data structures for efficient storage of data and high-level manipulations.'}\n",
      "{'library': 'Scikit-Learn', 'description': 'Scikit-Learn is a popular library for machine learning in Python. It provides tools to build, train, evaluate, and deploy machine learning algorithms.'}\n",
      "{'library': 'Matplotlib', 'description': 'Matplotlib is a Python plotting library for creating publication quality plots. It can produce line graphs, histograms, power spectra, bar charts, and more.'}\n",
      "{'library': 'Seaborn', 'description': 'Seaborn is a graphical library in Python for drawing statistical graphics. It provides a high level interface for drawing attractive statistical graphics.'}\n",
      "{'library': 'NLTK', 'description': 'NLTK is a Python library for natural language processing. It provides a wide range of tools for processing text, including tokenization, tagging, parsing, and more.'}\n",
      "{'library': 'TensorFlow', 'description': 'TensorFlow is an open-source library for machine learning in Python. It provides a complete infrastructure for building, training, and deploying machine learning models.'}\n",
      "{'library': 'Keras', 'description': 'Keras is an API for building neural networks in Python. It provides a simple and efficient way to create, train, and evaluate deep learning models.'}\n",
      "{'library': 'sciPy', 'description': 'SciPy is a library for scientific computing in Python. It provides a range of tools for numerical integration, linear algebra, optimization, and more.'}\n",
      "{'library': 'OpenCV', 'description': 'OpenCV is a library for computer vision in Python. It provides functions for image analysis, feature detection, and more.'}\n",
      "{'library': 'PyTorch', 'description': 'PyTorch is an open-source machine learning library for Python. It provides a wide range of tools for developing, training, and evaluating neural networks.'}\n",
      "{'library': 'BeautifulSoup', 'description': 'BeautifulSoup is a library for extracting data from HTML and XML documents. It provides a simple way to extract structured information from web pages.'}\n",
      "{'library': 'Requests', 'description': 'Requests is a library for making HTTP requests in Python. It provides features to handle cookies, redirects, connection timeouts, and more.'}\n",
      "{'library': 'Flask', 'description': 'Flask is a micro web framework for Python. It provides the tools to quickly build lightweight web applications.'}\n",
      "{'library': 'pyspark', 'description': 'pyspark is a library for distributed computing in Python. It provides tools for parallel processing on clusters of machines.'}\n",
      "{'library': 'Pillow', 'description': 'Pillow is a library for manipulating images in Python. It provides a range of features for manipulating, resizing, and transforming images.'}\n",
      "{'library': 'Scrapy', 'description': 'Scrapy is a library for extracting data from web pages. It provides a convenient way to crawl websites and extract structured information.'}\n",
      "{'library': 'pygame', 'description': 'pygame is a library for creating games in Python. It provides tools for making graphical user interfaces, playing sounds, and animating art.'}\n",
      "{'library': 'django', 'description': 'Django is a web framework for Python. It provides the tools and libraries for building powerful web applications.'}\n",
      "{'library': 'statsmodels', 'description': 'statsmodels is a library for statistical analysis in Python. It provides tools for fitting and testing statistical models.'}\n",
      "{'library': 'pytz', 'description': 'pytz is a library for working with time zones in Python. It provides tools to convert times between different time zones.'}\n",
      "{'library': 'xarray', 'description': 'xarray is a library for analyzing multi-dimensional arrays and datasets in Python. It provides a powerful framework for data analysis and visualization.'}\n",
      "{'library': 'bokeh', 'description': 'Bokeh is a library for creating interactive plots and dashboards in Python. It provides a high level interface for drawing attractive graphics.'}\n",
      "{'library': 'pyglet', 'description': 'pyglet is a library for multimedia programming in Python. It provides features for playing 3D graphics and other multimedia.'}\n",
      "{'library': 'Sphinx', 'description': 'Sphinx is a library for creating documentation in Python. It provides tools for building, writing, and maintaining comprehensive documentation.'}\n",
      "{'library': 'pytest', 'description': 'pytest is a library for testing Python code. It provides tools for writing and running tests in an automated way.'}\n",
      "{'library': 'networkx', 'description': 'networkx is a Library for analyzing networks and graphs in Python. It provides tools for constructing, analyzing, and visualizing graphs.'}\n",
      "{'library': 'NumExpr', 'description': 'NumExpr is a library for efficiently calculating numerical expressions in Python. It provides an array-oriented approach for processing large datasets.'}\n",
      "{'library': 'jupyter', 'description': 'Jupyter is a library for interactive computing in Python. It provides tools for creating documents containing live code, equations, and visualizations.'}\n",
      "{'library': 'SymPy', 'description': 'SymPy is a library for symbolic mathematics in Python. It provides tools for solving equations, manipulating expressions, and performing symbolic calculations.'}\n",
      "{'library': 'scikit-image', 'description': 'scikit-image is a library for image processing in Python. It provides algorithms for analyzing, transforming, and manipulating images.'}\n",
      "{'library': 'pySerial', 'description': 'pySerial is a library for communicating with serial ports in Python. It provides tools for sending and receiving data on serial and USB connections.'}\n",
      "{'library': 'lxml', 'description': 'lxml is a library for processing XML and HTML documents in Python. It provides powerful features for parsing, validating, and manipulating XML and HTML documents.'}\n",
      "{'library': 'Paramiko', 'description': 'Paramiko is a library for secure file transfers in Python. It provides an SSH2 protocol implementation for connecting to remote machines.'}\n",
      "{'library': 'PyYAML', 'description': 'PyYAML is a library for working with YAML files in Python. It provides features for parsing, creating, modifying, and saving YAML documents.'}\n",
      "{'library': 'Numba', 'description': 'Numba is a library for optimizing numerical code in Python. It provides tools for compiling Python code into faster native instructions.'}\n",
      "{'library': 'SciPy.optimize', 'description': 'SciPy.optimize is a library for optimizing functions in Python. It provides a range of algorithms for finding minima and maxima of functions.'}\n",
      "{'library': 'cProfile', 'description': 'cProfile is a library for profiling Python code. It provides a simple way to measure execution time and identify bottlenecks in code.'}\n",
      "{'library': 'SystemML', 'description': 'SystemML is a library for machine learning in Python. It provides a high-level API for developing, training, and evaluating machine learning models.'}\n",
      "{'library': 'PyODBC', 'description': 'PyODBC is a library for working with databases in Python. It provides a high-level interface for connecting to and querying relational databases.'}\n",
      "{'library': 'SymEngine', 'description': 'SymEngine is a library for symbolic computation in Python. It provides a unified interface for manipulating mathematical expressions and performing symbolic calculations.'}\n",
      "{'library': 'ggplot', 'description': 'ggplot is a library for creating beautiful graphics in Python. It provides a high level interface for drawing statistical graphics with layered components.'}\n",
      "{'library': 'Shapely', 'description': 'Shapely is a library for manipulating and analyzing geometric objects in Python. It provides features for calculating areas and distances, constructing shapes, and more.'}\n",
      "{'library': 'pygsheets', 'description': 'pygsheets is a library for working with Google Sheets in Python. It provides high-level functions for interacting with Google Sheets spreadsheets.'}\n",
      "{'library': 'SimpleCV', 'description': 'SimpleCV is a library for computer vision in Python. It provides functions for image processing, feature detection, and more.'}\n",
      "{'library': 'pandasql', 'description': 'pandasql is a library for writing SQL queries in Python. It provides an elegant way to query pandas data frames using SQL syntax.'}\n",
      "{'library': 'twisted', 'description': 'twisted is a library for asynchronous network programming in Python. It provides a wide range of tools for building and working with asynchronous services.'}\n",
      "{'library': 'igraph', 'description': 'igraph is a library for analyzing graphs and networks in Python. It provides algorithms for measuring centrality, traversing graphs, and more.'}\n",
      "{'library': 'PyMC3', 'description': 'PyMC3 is a library for probabilistic programming in Python. It provides high-level tools for building, fitting, and evaluating probabilistic models.'}\n",
      "{'library': 'Biopython', 'description': 'Biopython is a library for working with biological data in Python. It provides tools for reading and writing sequence data, performing sequence analysis, and more.'}\n",
      "{'library': 'cffi', 'description': 'cffi is a library for calling C functions from Python. It provides support for interacting with dynamic libraries and low-level operations.'}\n",
      "{'library': 'PyQt', 'description': 'PyQt is a library for building graphical user interfaces in Python. It provides a comprehensive set of widgets and other GUI components.'}\n",
      "{'library': 'pyspark.sql', 'description': 'pyspark.sql is a library for working with structured data in Python. It provides a high-level interface for processing data frames and running SQL queries.'}\n"
     ]
    }
   ],
   "source": [
    "# Execute the search query\n",
    "response = es.search(index=py_indexname, query=query, size=100)\n",
    "\n",
    "# Extract the results\n",
    "results = response[\"hits\"][\"hits\"]\n",
    "\n",
    "# Print the documents\n",
    "for result in results:\n",
    "    print(result[\"_source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can also see our data in Elasticsearch Kibana \"Discover\" tab\n",
    "\n",
    "![ES](./es.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregations\n",
    "* ES supports aggregations to perform analytics and gather insights from the data. \n",
    "* Library provides functions to build and execute aggregations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index exists\n",
      "Data successfully indexed in the destination index.\n"
     ]
    }
   ],
   "source": [
    "# Create an index\n",
    "indexname = 'prices'\n",
    "es.indices.create(index=indexname)\n",
    "\n",
    "# Check if an index exists\n",
    "if es.indices.exists(index=indexname):\n",
    "    print(\"Index exists\")\n",
    "else:\n",
    "    print(\"Index doesn't exist.\")\n",
    "\n",
    "actions = [\n",
    "    {\"_index\": indexname, \n",
    "     \"_id\": i, \n",
    "     \"_source\": {\n",
    "          \"product\": \"example\" + str(i),\n",
    "          \"price\": 3.20 + i*0.75}\n",
    "    }\n",
    "    for i in range(20)\n",
    "]\n",
    "\n",
    "try:\n",
    "    bulk(es, actions)\n",
    "    print(\"Data successfully indexed in the destination index.\")\n",
    "except BulkIndexError as e:\n",
    "    print(\"Failed to index documents:\")\n",
    "    for err in e.errors:\n",
    "        print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'count': 20, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = {\n",
    "        \"match_all\": {}\n",
    "}\n",
    "    \n",
    "es.count(index=indexname, query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'product': 'example0', 'price': 3.2}\n",
      "{'product': 'example1', 'price': 3.95}\n",
      "{'product': 'example2', 'price': 4.7}\n",
      "{'product': 'example3', 'price': 5.45}\n",
      "{'product': 'example4', 'price': 6.2}\n",
      "{'product': 'example5', 'price': 6.95}\n",
      "{'product': 'example6', 'price': 7.7}\n",
      "{'product': 'example7', 'price': 8.45}\n",
      "{'product': 'example8', 'price': 9.2}\n",
      "{'product': 'example9', 'price': 9.95}\n",
      "{'product': 'example10', 'price': 10.7}\n",
      "{'product': 'example11', 'price': 11.45}\n",
      "{'product': 'example12', 'price': 12.2}\n",
      "{'product': 'example13', 'price': 12.95}\n",
      "{'product': 'example14', 'price': 13.7}\n",
      "{'product': 'example15', 'price': 14.45}\n",
      "{'product': 'example16', 'price': 15.2}\n",
      "{'product': 'example17', 'price': 15.95}\n",
      "{'product': 'example18', 'price': 16.7}\n",
      "{'product': 'example19', 'price': 17.45}\n"
     ]
    }
   ],
   "source": [
    "# Execute the search query\n",
    "response = es.search(index=indexname, query=query, size=20)\n",
    "\n",
    "# Extract the results\n",
    "results = response[\"hits\"][\"hits\"]\n",
    "\n",
    "# Print the documents\n",
    "for result in results:\n",
    "    print(result[\"_source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Price: 10.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7l/srp8f0g91vxc5k32qtk6bwym0000gn/T/ipykernel_10552/22862089.py:12: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  response = es.search(index=indexname, body=aggregation_query)\n"
     ]
    }
   ],
   "source": [
    "aggregation_query = {\n",
    "    \"aggs\": {\n",
    "        \"avg_price\": {\n",
    "            \"avg\": {\n",
    "                \"field\": \"price\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Execute the aggregation query\n",
    "response = es.search(index=indexname, body=aggregation_query)\n",
    "\n",
    "# Get the average price from the response\n",
    "avg_price = response['aggregations']['avg_price']['value']\n",
    "\n",
    "print(f\"Average Price: {round(avg_price,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing all created indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.delete(index=indexname)\n",
    "es.indices.delete(index=py_indexname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Thank you!\n",
    "---\n",
    "\n",
    "* I hope you found this notebook on ElasticSearch and Python helpful and insightful. \n",
    "* If you have any questions, suggestions, or just want to connect, feel free to reach out to me on [LinkedIn](https://www.linkedin.com/in/natalia-szczepanek/).\n",
    "\n",
    "**Let's continue the conversation, collaborate, and stay connected!**\n",
    "\n",
    "---\n",
    "\n",
    "## Happy coding!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
